{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import os\n",
    "os.getcwd()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree , metrics, preprocessing\n",
    "import os\n",
    "%matplotlib inline \n",
    "from IPython.display import Image\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "#import sklearn\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "plt.style.use('fivethirtyeight')\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from matplotlib import animation,rc\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import codecs\n",
    "from subprocess import check_output\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.tools as tls\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer  #could have used tf-idf feature extractor\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openapi-codec in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (1.3.2)\n",
      "Requirement already satisfied: coreapi>=2.2.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from openapi-codec) (2.3.3)\n",
      "Requirement already satisfied: uritemplate in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from coreapi>=2.2.0->openapi-codec) (4.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from coreapi>=2.2.0->openapi-codec) (2.27.1)\n",
      "Requirement already satisfied: coreschema in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from coreapi>=2.2.0->openapi-codec) (0.0.4)\n",
      "Requirement already satisfied: itypes in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from coreapi>=2.2.0->openapi-codec) (1.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from coreschema->coreapi>=2.2.0->openapi-codec) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from requests->coreapi>=2.2.0->openapi-codec) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from requests->coreapi>=2.2.0->openapi-codec) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from requests->coreapi>=2.2.0->openapi-codec) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from requests->coreapi>=2.2.0->openapi-codec) (2.0.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from jinja2->coreschema->coreapi>=2.2.0->openapi-codec) (2.0.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install openapi-codec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytest-warnings in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (0.3.1)\n",
      "Requirement already satisfied: pytest in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pytest-warnings) (7.1.2)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pytest->pytest-warnings) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pytest->pytest-warnings) (0.4.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pytest->pytest-warnings) (21.4.0)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pytest->pytest-warnings) (1.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pytest->pytest-warnings) (21.3)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pytest->pytest-warnings) (1.2.3)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pytest->pytest-warnings) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pytest->pytest-warnings) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from packaging->pytest->pytest-warnings) (3.0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytest-warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pybase64 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pybase64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requires.io in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (0.2.6)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from requires.io) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.0.0->requires.io) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.0.0->requires.io) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.0.0->requires.io) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.0.0->requires.io) (2.0.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requires.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (5.8.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from plotly) (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipython in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (8.0.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\program files\\python39\\lib\\site-packages (from ipython) (56.0.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.18.1)\n",
      "Requirement already satisfied: pygments in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (2.11.2)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.4.4)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.1.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (3.0.26)\n",
      "Requirement already satisfied: black in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (21.12b0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.5)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from black->ipython) (2.4.1)\n",
      "Requirement already satisfied: pathspec<1,>=0.9.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from black->ipython) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from black->ipython) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from black->ipython) (4.0.1)\n",
      "Requirement already satisfied: tomli<2.0.0,>=0.2.6 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from black->ipython) (1.2.3)\n",
      "Requirement already satisfied: click>=7.1.2 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from black->ipython) (8.0.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython) (2.0.5)\n",
      "Requirement already satisfied: executing in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython) (0.8.2)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from asttokens->stack-data->ipython) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: graphviz in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (0.20)\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from seaborn) (1.22.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from seaborn) (1.8.0)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=2.2->seaborn) (4.33.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=2.2->seaborn) (9.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (3.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.22.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.22.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement os (from versions: none)\n",
      "ERROR: No matching distribution found for os\n"
     ]
    }
   ],
   "source": [
    "pip install os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\users\\dhanu\\appdata\\roaming\\python\\python39\\site-packages (22.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pip --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\\\sports predition\\\\cricket final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install os-sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRM=pd.read_csv(\"Trainmatches.csv\")\n",
    "TRM.index=TRM[\"id\"]\n",
    "TRD=pd.read_csv(\"TrainDeliveries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Intially we plot a histogram to find number of matches that each team won in IPL and also find which teams stood out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_played_byteams=pd.concat([TRM['team1'],TRM['team2']])\n",
    "matches_played_byteams=matches_played_byteams.value_counts().reset_index()\n",
    "matches_played_byteams.columns=['Team','Total Matches']\n",
    "matches_played_byteams['wins']=TRM['winner'].value_counts().reset_index()['winner']\n",
    "matches_played_byteams.set_index('Team',inplace=True)\n",
    "\n",
    "trace1 = go.Bar(\n",
    "    x=matches_played_byteams.index,\n",
    "    y=matches_played_byteams['Total Matches'],\n",
    "    name='Total Matches'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=matches_played_byteams.index,\n",
    "    y=matches_played_byteams['wins'],\n",
    "    name='Matches Won'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    barmode='stack'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='stacked-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows that total matches that each team played and the number of matches they won."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DROPPING THE NULL VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking up the null values and damaged data values in the dataset and removing them will give the correct ouput .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns=TRM.columns[TRM.isnull().any()]\n",
    "TRM[null_columns].isnull().sum()\n",
    "\n",
    "print(TRM[TRM[\"winner\"].isnull()][null_columns])\n",
    "# Dropping the row \n",
    "TRM=TRM.drop(index=301)\n",
    "print(TRM[TRM[\"winner\"].isnull()][null_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the feature table to train our data and create the table . All the matches are identified by the match_id so we can make this field as the primary_index of the feature table and we have to find that total matches played . From the given dataset we can infer that match_id lies from 1 to 500 matches. Now setting up the team details like which teams are going to play in the match on the respective id's.So add Team A and Team B columns to the FT Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Feature Table\n",
    "FT=pd.DataFrame()\n",
    "\n",
    "# Making match_id as the index\n",
    "FT[\"match_id\"]=TRM[\"id\"]\n",
    "FT.index=FT[\"match_id\"]\n",
    "\n",
    "print('Total Matches Played:',TRM.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now setting up the team details like which teams are going to play in the match on the respective id's.So add Team A and Team B columns to the FT Dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Team Deatils\n",
    "FT[\"Team A\"]=TRM[\"team1\"]\n",
    "FT[\"Team B\"]=TRM[\"team2\"]\n",
    "FT = FT.drop('match_id', 1)\n",
    "print('Teams:',FT['Team A'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEASON FEATURE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time is a important feature for prediciting match outcome.Since the time period reputates the growth and their downfalls statistically.In this dataset season feature act as the time period of every match.Now we justify why we taken season as our feature.We also need winning_team result to explorate their winning structure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding season and winner to the feature table\n",
    "FT[\"season\"]=TRM[\"season\"]\n",
    "FT[\"winner\"]=TRM[\"winner\"]\n",
    "\n",
    "#creating the season and team list\n",
    "season_list=FT['season'].unique()\n",
    "team_list=FT['Team A'].unique()\n",
    "\n",
    "#Now check the frequency of each team won during every season\n",
    "\n",
    "temp_data=pd.DataFrame() # Creating a temporary dataframe    \n",
    "temp_data[\"Team\"]=team_list\n",
    "temp_data.index=temp_data[\"Team\"]\n",
    "\n",
    "for s in season_list:\n",
    "    winner_season=FT.loc[FT['season']== s,\"winner\"] # get the series of winners at the particular season\n",
    "    t=winner_season.value_counts() # count the value of winning_count of each team\n",
    "    t=t.to_frame() # Series is not efficient to work converting to a dataframe\n",
    "    temp_data[\"win_count\"]=t[\"winner\"] \n",
    "    temp_data['win_count']=temp_data['win_count'].fillna(0)\n",
    "    temp_data['win_count']=temp_data['win_count'].astype(int)\n",
    "    tit=\"season \"+str(s)\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    temp_data.plot(kind='bar',title=tit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence from the above bar plots we can infer that the team_performance varies seasonally.So we concluded the seasonal values as an important feature to the feature table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOSS FEATURE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams=['Team1','Team2','Team3','Team4','Team5','Team6','Team7','Team8','Team9','Team10','Team11']\n",
    "t=pd.Series(teams)\n",
    "# finding the frequency of toss winners and the match winners to correlate\n",
    "temp_toss_winner=pd.DataFrame()\n",
    "temp_toss_winner['Team']=t.values\n",
    "temp_match_winner=pd.DataFrame()\n",
    "temp_match_winner['Team']=t.values\n",
    "\n",
    "#Caluclating toss_winning and match winning frequency of each team\n",
    "temp_toss_winner['Count'] = temp_toss_winner['Team'].map(TRM['toss_winner'].value_counts())\n",
    "temp_match_winner['Count']=temp_match_winner['Team'].map(TRM['winner'].value_counts())\n",
    "\n",
    "plt.subplots(figsize=(8,6))\n",
    "ax=TRM['toss_winner'].value_counts().plot.bar(width=0.8)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))\n",
    "plt.title(\"Toss Winner\")\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(figsize=(8,6))\n",
    "ax=TRM['winner'].value_counts().plot.bar(width=0.8)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))\n",
    "plt.title(\"Match Winner\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to know whether toss won act as a important role in winning decision.To check we have to visulaize a probablitic calculation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=TRM[TRM['toss_winner']==TRM['winner']]\n",
    "slices=[len(df),(577-len(df))]\n",
    "labels=['yes','no']\n",
    "plt.pie(slices,labels=labels,startangle=90,shadow=True,explode=(0,0),autopct='%1.1f%%',colors=['r','g'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this correaltion graph we can identify that toss winning also act as a major feature in predicting the result .From the graph we can infer that 43.7% toss winners are match winners.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the toss_winner to the feature table\n",
    "FT[\"toss_winner\"]=TRM[\"toss_winner\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VENUE FEATURE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,15))\n",
    "ax = TRM['venue'].value_counts().sort_values(ascending=True).plot.barh(width=.9)\n",
    "ax.set_xlabel('Grounds')\n",
    "ax.set_ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEAM DELIVERIES\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RUNS PER OVER ACROSS SEASON\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_per_over = TRD.pivot_table(index=['over'],columns='batting_team',values='total_runs',aggfunc=sum)\n",
    "runs_per_over[(matches_played_byteams[matches_played_byteams['Total Matches']>50].index)].plot(color=[\"b\", \"r\", \"#Ffb6b2\", \"g\",'brown','y','#6666ff','black','#FFA500']) #plotting graphs for teams that have played more than 100 matches\n",
    "x=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "plt.xticks(x)\n",
    "plt.ylabel('total runs scored')\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(16,12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this visualization we can say that we have to calculate the batting and bowling average of each team to calcuate the overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batting_Averager(df):\n",
    "    over_average=pd.DataFrame()\n",
    "    overs=list(range(1, 21))\n",
    "    o_a=[]\n",
    "    o=pd.Series(overs)\n",
    "    over_average['overs']=o.values\n",
    "    for i in overs:\n",
    "        over_temp_frame=df.loc[df['over']== i]\n",
    "        total_bruns=over_temp_frame['bye_runs'].sum()\n",
    "        total_lbruns=over_temp_frame['legbye_runs'].sum()\n",
    "        b_non_zero=over_temp_frame.loc[over_temp_frame['batsman_runs'] != 0,\"batsman_runs\"].sum()\n",
    "        b_dot=over_temp_frame.loc[over_temp_frame['batsman_runs']==0,\"batsman_runs\"].count()\n",
    "        b_dis=over_temp_frame.loc[over_temp_frame['dismissal_kind'] != 'NaN',\"dismissal_kind\"].count()\n",
    "        oa=(1*total_bruns+1*total_lbruns+2*b_non_zero-1*b_dot+-3*b_dis)/5\n",
    "        o_a.append(oa)\n",
    "    o_a=pd.Series(o_a)\n",
    "    over_average['average']=o_a.values\n",
    "    bat_av=over_average[\"average\"].mean()\n",
    "    return bat_av\n",
    "    \n",
    "\n",
    "def Bowling_Averager(df):\n",
    "    over_average=pd.DataFrame()\n",
    "    overs=list(range(1, 21))\n",
    "    o_a=[]\n",
    "    o=pd.Series(overs)\n",
    "    over_average['overs']=o.values\n",
    "    for i in overs:\n",
    "        over_temp_frame=df.loc[df['over']== i]\n",
    "        total_wr=over_temp_frame['wide_runs'].sum()\n",
    "        total_nb=over_temp_frame['noball_runs'].sum()\n",
    "        total_pr=over_temp_frame['penalty_runs'].sum()\n",
    "        total_er=over_temp_frame['extra_runs'].sum()\n",
    "        b_non_zero=over_temp_frame.loc[over_temp_frame['total_runs'] != 0,\"total_runs\"].sum()\n",
    "        b_dot=over_temp_frame.loc[over_temp_frame['total_runs']==0,\"total_runs\"].count()\n",
    "        b_dis=over_temp_frame.loc[over_temp_frame['dismissal_kind'] != 'NaN',\"dismissal_kind\"].count()\n",
    "        oa=(-1*total_wr+-1*total_nb+-2*total_pr+-1*total_er+-2*b_non_zero+5*b_dot+10*b_dis)/7\n",
    "        o_a.append(oa)\n",
    "    o_a=pd.Series(o_a)\n",
    "    over_average['average']=o_a.values\n",
    "    bow_av=over_average[\"average\"].mean()\n",
    "    return(bow_av)\n",
    "\n",
    "\n",
    "\n",
    "#creating team_performance dataframe\n",
    "team_performance=pd.DataFrame()\n",
    "team_performance[\"match_id\"]=TRM[\"id\"]\n",
    "team_performance.index=team_performance[\"match_id\"]\n",
    "team_performance[\"Team_A_Batting_Average\"]=0.0\n",
    "team_performance[\"Team_A_Bowling_Average\"]=0.0\n",
    "team_performance[\"Team_A_Total_Runs\"]=0\n",
    "team_performance[\"Team_B_Batting_Average\"]=0.0\n",
    "team_performance[\"Team_B_Bowling_Average\"]=0.0\n",
    "team_performance[\"Team_B_Total_Runs\"]=0\n",
    "team_performance[\"Team_A_overall\"]=0.0\n",
    "team_performance[\"Team_B_overall\"]=0.0\n",
    "team_performance[\"super_over\"]='0'\n",
    "\n",
    "# creating match_id list\n",
    "match_id_list=TRM[\"id\"].unique()\n",
    "overs_list=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "\n",
    "for m in match_id_list:\n",
    "    match_frame=TRD.loc[TRD[\"match_id\"]==m]\n",
    "    temp=FT.loc[m,\"Team A\":\"Team B\"]\n",
    "    team_dict=temp.to_dict()\n",
    "    FLAG=False\n",
    "    team_perform_dict={\"match_id\":m,\"Team_A_Batting_Average\":0.0,\"Team_A_Bowling_Average\":0.0,\"Team_A_Total_Runs\":0,\"Team_B_Batting_Average\":0.0,\"Team_B_Bowling_Average\":0.0,\"Team_B_Total_Runs\":0,\"Team_A_overall\":0.0,\"Team_B_overall\":0.0,\"super_over\":'0'}\n",
    "    super_over=match_frame['is_super_over'].sum()\n",
    "    \n",
    "    if super_over==0:\n",
    "        innings=match_frame[\"inning\"].unique()\n",
    "        super_over_innings=[]\n",
    "    else :\n",
    "        super_over_run={\"Team_A_run\":0,\"Team_B_run\":0}\n",
    "        FLAG=True\n",
    "        super_over_innings=[3,4]\n",
    "    \n",
    "    for i in innings:\n",
    "        innings_frame=pd.DataFrame()\n",
    "        innings_frame=match_frame.loc[match_frame['inning'] == i]\n",
    "        batting_team=innings_frame.loc[innings_frame['inning']== i,\"batting_team\"].values[0]\n",
    "        bowling_team=innings_frame.loc[innings_frame['inning']== i,\"bowling_team\"].values[0]\n",
    "        \n",
    "        if(team_dict['Team A']==batting_team):\n",
    "            batting_team_frame=innings_frame[['over','ball','bye_runs','legbye_runs','batsman_runs','dismissal_kind']]\n",
    "            bowling_team_frame=innings_frame[['over','ball','wide_runs','noball_runs','penalty_runs','extra_runs','total_runs','dismissal_kind']]\n",
    "            team_perform_dict[\"Team_A_Batting_Average\"]=Batting_Averager(batting_team_frame)\n",
    "            team_perform_dict[\"Team_B_Bowling_Average\"]=Bowling_Averager(bowling_team_frame)\n",
    "            team_perform_dict[\"Team_A_Total_Runs\"] =innings_frame['total_runs'].sum()\n",
    "            \n",
    "        elif(team_dict['Team B']==batting_team):\n",
    "            batting_team_frame=innings_frame[['over','ball','bye_runs','legbye_runs','batsman_runs','dismissal_kind']]\n",
    "            bowling_team_frame=innings_frame[['over','ball','wide_runs','noball_runs','penalty_runs','extra_runs','total_runs','dismissal_kind']]\n",
    "            team_perform_dict[\"Team_B_Batting_Average\"]=Batting_Averager(batting_team_frame)\n",
    "            team_perform_dict[\"Team_A_Bowling_Average\"]=Bowling_Averager(bowling_team_frame)\n",
    "            team_perform_dict[\"Team_B_Total_Runs\"]=innings_frame['total_runs'].sum()\n",
    "        \n",
    "    for i in super_over_innings:\n",
    "        innings_frame=pd.DataFrame()\n",
    "        innings_frame=match_frame.loc[match_frame['inning']==i]\n",
    "        batting_team=innings_frame.loc[innings_frame['inning']== i,\"batting_team\"].values[0]\n",
    "        if(team_dict['Team A']==batting_team):\n",
    "            super_over_run[\"Team_A_run\"]=innings_frame['total_runs'].sum()\n",
    "        elif(team_dict['Team B']==batting_team):\n",
    "            super_over_run[\"Team_B_run\"]=innings_frame['total_runs'].sum()\n",
    "\n",
    "    if FLAG:\n",
    "        if super_over_run[\"Team_A_run\"]>super_over_run[\"Team_B_run\"]:\n",
    "            team_perform_dict['super_over']='A'\n",
    "        elif super_over_run[\"Team_B_run\"]>super_over_run[\"Team_A_run\"]:\n",
    "            team_perform_dict['super_over']='B'\n",
    "            \n",
    "    team_perform_dict[\"Team_A_overall\"]=(team_perform_dict[\"Team_A_Batting_Average\"]+team_perform_dict[\"Team_A_Bowling_Average\"])/2\n",
    "    team_perform_dict[\"Team_B_overall\"]=(team_perform_dict[\"Team_B_Batting_Average\"]+team_perform_dict[\"Team_B_Bowling_Average\"])/2\n",
    "\n",
    "    \n",
    "    df=pd.DataFrame([team_perform_dict],columns=team_perform_dict.keys())\n",
    "    df.index=df[\"match_id\"]\n",
    "    match=df[\"match_id\"].unique()\n",
    "    team_performance.loc[match,:]= df.loc[df[\"match_id\"],:]\n",
    "    \n",
    "\n",
    "team_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLAYER OF EACH MATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Player of the match will be the one who denots the extraordinary work and most probably they belong to the winning team .So we may consider this feature also a bonus one to enhance our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_match_frame=pd.DataFrame()\n",
    "player_match_frame[\"match_id\"]=TRM[\"id\"]\n",
    "player_match_frame.index=player_match_frame[\"match_id\"]\n",
    "player_match_frame[\"man_of_match\"]='NOT_IN_TEAM'\n",
    "match_id_list=TRM[\"id\"].unique()\n",
    "\n",
    "for m in match_id_list:\n",
    "    player=TRM.loc[TRM['id']== m,\"player_of_match\"].values[0]\n",
    "    match_frame=TRD.loc[TRD[\"match_id\"]==m]\n",
    "    temp=FT.loc[m,\"Team A\":\"Team B\"]\n",
    "    team_dict=temp.to_dict()\n",
    "    TEAM_A_BATSMAN=match_frame.loc[match_frame['batting_team']==team_dict[\"Team A\"],[\"batsman\",\"non_striker\"]]\n",
    "    TEAM_A_BOWLERS=match_frame.loc[match_frame['bowling_team']==team_dict[\"Team A\"],[\"bowler\"]]\n",
    "    TEAM_A_MEMBERS=set(list(TEAM_A_BATSMAN[\"batsman\"].unique())+list(TEAM_A_BATSMAN[\"non_striker\"].unique())+list(TEAM_A_BOWLERS[\"bowler\"].unique()))\n",
    "    TEAM_B_BATSMAN=match_frame.loc[match_frame['batting_team']==team_dict[\"Team B\"],[\"batsman\",\"non_striker\"]]\n",
    "    TEAM_B_BOWLERS=match_frame.loc[match_frame['bowling_team']==team_dict[\"Team B\"],[\"bowler\"]]\n",
    "    TEAM_B_MEMBERS=set(list(TEAM_B_BATSMAN[\"batsman\"].unique())+list(TEAM_B_BATSMAN[\"non_striker\"].unique())+list(TEAM_B_BOWLERS[\"bowler\"].unique()))\n",
    "    if player in TEAM_A_MEMBERS:\n",
    "        player_match_frame.at[m, 'man_of_match'] = 'A'\n",
    "    elif player in TEAM_B_MEMBERS:\n",
    "        player_match_frame.at[m,\"man_of_match\"]='B'\n",
    "player_match_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_frame=pd.DataFrame()\n",
    "winner_frame[\"match_id\"]=TRM[\"id\"]\n",
    "winner_frame.index=winner_frame[\"match_id\"]\n",
    "winner_frame[\"winner\"]=0\n",
    "match_id_list=TRM[\"id\"].unique()\n",
    "\n",
    "for m in match_id_list:\n",
    "    winner=TRM.loc[TRM['id']== m,\"winner\"].values[0]\n",
    "    temp=FT.loc[m,\"Team A\":\"Team B\"]\n",
    "    team_dict=temp.to_dict()\n",
    "    if(winner==team_dict[\"Team A\"]):\n",
    "        winner_frame.at[m, 'winner'] = 0\n",
    "    elif(winner==team_dict[\"Team B\"]):\n",
    "        winner_frame.at[m,'winner']=1\n",
    "        \n",
    "winner_frame\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this analytics we can infer that player_of_match given in TrainMatchesdataset is collapsed and they are giving the mismatched result.So We can neglect this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARATION OF FEATURE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batting_Averager(df):\n",
    "    over_average=pd.DataFrame()\n",
    "    overs=list(range(1, 21))\n",
    "    o_a=[]\n",
    "    o=pd.Series(overs)\n",
    "    over_average['overs']=o.values\n",
    "    for i in overs:\n",
    "        over_temp_frame=df.loc[df['over']== i]\n",
    "        total_bruns=over_temp_frame['bye_runs'].sum()\n",
    "        total_lbruns=over_temp_frame['legbye_runs'].sum()\n",
    "        b_non_zero=over_temp_frame.loc[over_temp_frame['batsman_runs'] != 0,\"batsman_runs\"].sum()\n",
    "        b_dot=over_temp_frame.loc[over_temp_frame['batsman_runs']==0,\"batsman_runs\"].count()\n",
    "        b_dis=over_temp_frame.loc[over_temp_frame['dismissal_kind'] != 'NaN',\"dismissal_kind\"].count()\n",
    "        oa=(1*total_bruns+1*total_lbruns+2*b_non_zero+-1*b_dot+-3*b_dis)/5\n",
    "        o_a.append(oa)\n",
    "    o_a=pd.Series(o_a)\n",
    "    over_average['average']=o_a.values\n",
    "    bat_av=over_average[\"average\"].mean()\n",
    "    return bat_av\n",
    "    \n",
    "\n",
    "def Bowling_Averager(df):\n",
    "    over_average=pd.DataFrame()\n",
    "    overs=list(range(1, 21))\n",
    "    o_a=[]\n",
    "    o=pd.Series(overs)\n",
    "    over_average['overs']=o.values\n",
    "    for i in overs:\n",
    "        over_temp_frame=df.loc[df['over']== i]\n",
    "        total_wr=over_temp_frame['wide_runs'].sum()\n",
    "        total_nb=over_temp_frame['noball_runs'].sum()\n",
    "        total_pr=over_temp_frame['penalty_runs'].sum()\n",
    "        total_er=over_temp_frame['extra_runs'].sum()\n",
    "        b_non_zero=over_temp_frame.loc[over_temp_frame['total_runs'] != 0,\"total_runs\"].sum()\n",
    "        b_dot=over_temp_frame.loc[over_temp_frame['total_runs']==0,\"total_runs\"].count()\n",
    "        b_dis=over_temp_frame.loc[over_temp_frame['dismissal_kind'] != 'NaN',\"dismissal_kind\"].count()\n",
    "        oa=(-1*total_wr+-1*total_nb+-2*total_pr+-1*total_er+-2*b_non_zero+5*b_dot+10*b_dis)/7\n",
    "        o_a.append(oa)\n",
    "    o_a=pd.Series(o_a)\n",
    "    over_average['average']=o_a.values\n",
    "    bow_av=over_average[\"average\"].mean()\n",
    "    return(bow_av)\n",
    "\n",
    "\n",
    "\n",
    "def df_feature(TRM,TRD,T):\n",
    "    # Creating Feature Table\n",
    "    F_T=pd.DataFrame()\n",
    "\n",
    "    # Making match_id as the index\n",
    "    F_T[\"match_id\"]=TRM[\"id\"]\n",
    "    F_T.index=F_T[\"match_id\"]\n",
    "\n",
    "    # Adding Team Deatils\n",
    "    F_T[\"Team A\"]=TRM[\"team1\"]\n",
    "    F_T[\"Team B\"]=TRM[\"team2\"]\n",
    "\n",
    "    # Adding Season Feature\n",
    "    F_T[\"season\"]=TRM[\"season\"]\n",
    "\n",
    "    # Adding Toss Winner Feature\n",
    "    F_T[\"toss_winner\"]=TRM[\"toss_winner\"]\n",
    "\n",
    "    # Adding dl feature\n",
    "    F_T[\"dl_applied\"]=TRM[\"dl_applied\"]\n",
    "    \n",
    "    #Adding cross validation features\n",
    "    #creating team_performance dataframe\n",
    "    team_performance=pd.DataFrame()\n",
    "    team_performance[\"match_id\"]=TRM[\"id\"]\n",
    "    team_performance.index=team_performance[\"match_id\"]\n",
    "    team_performance[\"Team_A_Batting_Average\"]=0.0\n",
    "    team_performance[\"Team_A_Bowling_Average\"]=0.0\n",
    "    team_performance[\"Team_A_Total_Runs\"]=0.0\n",
    "    team_performance[\"Team_B_Batting_Average\"]=0.0\n",
    "    team_performance[\"Team_B_Bowling_Average\"]=0.0\n",
    "    team_performance[\"Team_B_Total_Runs\"]=0.0\n",
    "    team_performance[\"Team_A_overall\"]=0.0\n",
    "    team_performance[\"Team_B_overall\"]=0.0\n",
    "    team_performance[\"super_over\"]='0'\n",
    "\n",
    "    # creating match_id list\n",
    "    match_id_list=TRM[\"id\"].unique()\n",
    "    overs_list=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "\n",
    "    for m in match_id_list:\n",
    "        match_frame=TRD.loc[TRD[\"match_id\"]==m]\n",
    "        temp=F_T.loc[m,\"Team A\":\"Team B\"]\n",
    "        team_dict=temp.to_dict()\n",
    "        FLAG=False\n",
    "        team_perform_dict={\"match_id\":m,\"Team_A_Batting_Average\":0.0,\"Team_A_Bowling_Average\":0.0,\"Team_A_Total_Runs\":0,\"Team_B_Batting_Average\":0.0,\"Team_B_Bowling_Average\":0.0,\"Team_B_Total_Runs\":0,\"Team_A_overall\":0.0,\"Team_B_overall\":0.0,\"super_over\":0}\n",
    "        super_over=match_frame['is_super_over'].sum()\n",
    "    \n",
    "        if super_over==0:\n",
    "            innings=match_frame[\"inning\"].unique()\n",
    "            super_over_innings=[]\n",
    "        else :\n",
    "            super_over_run={\"Team_A_run\":0,\"Team_B_run\":0}\n",
    "            FLAG=True\n",
    "            super_over_innings=[3,4]\n",
    "    \n",
    "        for i in innings:\n",
    "            innings_frame=pd.DataFrame()\n",
    "            innings_frame=match_frame.loc[match_frame['inning'] == i]\n",
    "            batting_team=innings_frame.loc[innings_frame['inning']== i,\"batting_team\"].values[0]\n",
    "            bowling_team=innings_frame.loc[innings_frame['inning']== i,\"bowling_team\"].values[0]\n",
    "        \n",
    "            if(team_dict['Team A']==batting_team):\n",
    "                batting_team_frame=innings_frame[['over','ball','bye_runs','legbye_runs','batsman_runs','dismissal_kind']]\n",
    "                bowling_team_frame=innings_frame[['over','ball','wide_runs','noball_runs','penalty_runs','extra_runs','total_runs','dismissal_kind']]\n",
    "                team_perform_dict[\"Team_A_Batting_Average\"]=Batting_Averager(batting_team_frame)\n",
    "                team_perform_dict[\"Team_B_Bowling_Average\"]=Bowling_Averager(bowling_team_frame)\n",
    "                team_perform_dict[\"Team_A_Total_Runs\"] =innings_frame['total_runs'].sum()\n",
    "            \n",
    "            elif(team_dict['Team B']==batting_team):\n",
    "                batting_team_frame=innings_frame[['over','ball','bye_runs','legbye_runs','batsman_runs','dismissal_kind']]\n",
    "                bowling_team_frame=innings_frame[['over','ball','wide_runs','noball_runs','penalty_runs','extra_runs','total_runs','dismissal_kind']]\n",
    "                team_perform_dict[\"Team_B_Batting_Average\"]=Batting_Averager(batting_team_frame)\n",
    "                team_perform_dict[\"Team_A_Bowling_Average\"]=Bowling_Averager(bowling_team_frame)\n",
    "                team_perform_dict[\"Team_B_Total_Runs\"] =innings_frame['total_runs'].sum()\n",
    "        \n",
    "        for i in super_over_innings:\n",
    "            innings_frame=pd.DataFrame()\n",
    "            innings_frame=match_frame.loc[match_frame['inning']==i]\n",
    "            batting_team=innings_frame.loc[innings_frame['inning']== i,\"batting_team\"].values[0]\n",
    "            if(team_dict['Team A']==batting_team):\n",
    "                super_over_run[\"Team_A_run\"]=innings_frame['total_runs'].sum()\n",
    "            elif(team_dict['Team B']==batting_team):\n",
    "                super_over_run[\"Team_B_run\"]=innings_frame['total_runs'].sum()\n",
    "\n",
    "        if FLAG:\n",
    "            if super_over_run[\"Team_A_run\"]>super_over_run[\"Team_B_run\"]:\n",
    "                team_perform_dict['super_over']=1\n",
    "            elif super_over_run[\"Team_B_run\"]>super_over_run[\"Team_A_run\"]:\n",
    "                team_perform_dict['super_over']=2\n",
    "            \n",
    "        team_perform_dict[\"Team_A_overall\"]=(team_perform_dict[\"Team_A_Batting_Average\"]+team_perform_dict[\"Team_A_Bowling_Average\"])/2\n",
    "        team_perform_dict[\"Team_B_overall\"]=(team_perform_dict[\"Team_B_Batting_Average\"]+team_perform_dict[\"Team_B_Bowling_Average\"])/2\n",
    "\n",
    "    \n",
    "        df=pd.DataFrame([team_perform_dict],columns=team_perform_dict.keys())\n",
    "        df.index=df[\"match_id\"]\n",
    "        match=df[\"match_id\"].unique()\n",
    "        team_performance.loc[match,:]= df.loc[df[\"match_id\"],:]\n",
    "        \n",
    "    F_T[\"Team_A_Batting_Average\"]=team_performance[\"Team_A_Batting_Average\"]\n",
    "    F_T[\"Team_A_Bowling_Average\"]=team_performance[\"Team_A_Bowling_Average\"]\n",
    "    F_T[\"Team_A_Total_Runs\"]=team_performance[\"Team_A_Total_Runs\"]\n",
    "    F_T[\"Team_B_Batting_Average\"]=team_performance[\"Team_B_Batting_Average\"]\n",
    "    F_T[\"Team_B_Bowling_Average\"]=team_performance[\"Team_B_Bowling_Average\"]\n",
    "    F_T[\"Team_B_Total_Runs\"]=team_performance[\"Team_B_Total_Runs\"]\n",
    "    F_T[\"Team_A_overall\"]=team_performance[\"Team_A_overall\"]\n",
    "    F_T[\"Team_B_overall\"]=team_performance[\"Team_B_overall\"]\n",
    "    F_T[\"super_over\"]=team_performance[\"super_over\"]\n",
    "    \n",
    "    if(T):\n",
    "        #Winner Field\n",
    "        winner_frame=pd.DataFrame()\n",
    "        winner_frame[\"match_id\"]=TRM[\"id\"]\n",
    "        winner_frame.index=winner_frame[\"match_id\"]\n",
    "        winner_frame[\"winner\"]=0\n",
    "        match_id_list=TRM[\"id\"].unique()\n",
    "\n",
    "        for m in match_id_list:\n",
    "            winner=TRM.loc[TRM['id']== m,\"winner\"].values[0]\n",
    "            temp=F_T.loc[m,\"Team A\":\"Team B\"]\n",
    "            team_dict=temp.to_dict()\n",
    "            if(winner==team_dict[\"Team A\"]):\n",
    "                winner_frame.at[m, 'winner'] = 0\n",
    "            elif(winner==team_dict[\"Team B\"]):\n",
    "                winner_frame.at[m,'winner']=1\n",
    "            \n",
    "        #Adding Winner Field to F_T\n",
    "        F_T[\"winner\"]=winner_frame[\"winner\"]\n",
    "        \n",
    "    return F_T\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=True\n",
    "train=df_feature(TRM,TRD,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature=[\"season\", \"dl_applied\",\n",
    "               \"Team_A_Batting_Average\", \"Team_A_Bowling_Average\",\n",
    "               \"Team_A_Total_Runs\",\n",
    "                \"Team_B_Batting_Average\", \"Team_B_Bowling_Average\",\n",
    "               \"Team_B_Total_Runs\",\n",
    "                \"Team_A_overall\",\"Team_B_overall\",\"super_over\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[train_feature],train[\"winner\"], test_size = 0.2, random_state = 10)\n",
    "#one_hot_encoded_training_predictors=one_hot_encoded_training_predictors.drop('toss_winner_Team11',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING NAVIE_BAYES ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets \n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Predict Output \n",
    "predicted= model.predict(X_test)\n",
    "a = accuracy_score(y_test,predicted)\n",
    "print('The accuracy using NB is:',format(a*100))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, predicted)\n",
    "conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(conf_mat_normalized)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION TREE REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "DT_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit model\n",
    "DT_model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output \n",
    "predicted= DT_model.predict(X_test)\n",
    "a = accuracy_score(y_test,predicted)\n",
    "print('The accuracy using DecisionTreeRegressor is:',format(a*100))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, predicted)\n",
    "conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(conf_mat_normalized)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "SVC_model = svm.SVC()\n",
    "\n",
    "# Fit model\n",
    "SVC_model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output \n",
    "predicted= SVC_model.predict(X_test)\n",
    "a = accuracy_score(y_test,predicted)\n",
    "print('The accuracy using SVC Classifier is:',format(a*100))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, predicted)\n",
    "conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(conf_mat_normalized)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "RF_model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "# Fit model\n",
    "RF_model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output \n",
    "predicted= RF_model.predict(X_test)\n",
    "a = accuracy_score(y_test,predicted)\n",
    "print('The accuracy using RandomForest Classifier is:',format(a*100))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, predicted)\n",
    "conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(conf_mat_normalized)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
